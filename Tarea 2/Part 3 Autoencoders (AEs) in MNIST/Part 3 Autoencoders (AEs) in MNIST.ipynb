{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos desde keras, se normalizan las imagenes de modo que los pixeles queden descritos en el range [0,1], luegos se transforman en vectores unidimensionales y se parten en conjuntos disjuntos de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255. #and x_test\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "#Se extraen datos para hacer el set de validación\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=(1/6))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se pasa a usar los datos para una red de autoencoder feed forward, en donde las capas de este son densas. Para esto se re estructuraran los datos de entradas en forma de vector, es decir la matriz de 28 × 28 pasa a ser un vector de 784 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "X_val = x_val.reshape((len(x_val), np.prod(x_val.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección a) Se entrena un AE (1 hddn layer) para generar una representación de MNIST de d' = 2 ,8 ,32 ,64 . Se elije la función de perdida XXXXXXX  y el criterio del entrenamiento . Determine el porcentaje de compresión obtneido y el error de reconstrucción en cada caso. Se mojra el resulta si elegiumos un funcióin de activación reulo para el encoder o decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n",
      "c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n",
      "c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.3070 - val_loss: 0.2691\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2667 - val_loss: 0.2657\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2649 - val_loss: 0.2647\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2642 - val_loss: 0.2643\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2638 - val_loss: 0.2640\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2636 - val_loss: 0.2638\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2635 - val_loss: 0.2636\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2633 - val_loss: 0.2636\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2632 - val_loss: 0.2632\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2617 - val_loss: 0.2604\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2585 - val_loss: 0.2572\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2553 - val_loss: 0.2541\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.2525 - val_loss: 0.2516\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2502 - val_loss: 0.2493\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.2477 - val_loss: 0.2467\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2449 - val_loss: 0.2438\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2421 - val_loss: 0.2409\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2391 - val_loss: 0.2379\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.2362 - val_loss: 0.2350\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2333 - val_loss: 0.2321\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2306 - val_loss: 0.2294\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2278 - val_loss: 0.2266\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2251 - val_loss: 0.2240\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2225 - val_loss: 0.2214\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2201 - val_loss: 0.2191\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2179 - val_loss: 0.2169\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.2158 - val_loss: 0.2149\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2138 - val_loss: 0.2130\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2119 - val_loss: 0.2111\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2101 - val_loss: 0.2093\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2083 - val_loss: 0.2075\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2065 - val_loss: 0.2057\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.2047 - val_loss: 0.2040\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.2030 - val_loss: 0.2022\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.2013 - val_loss: 0.2005\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.1996 - val_loss: 0.1989\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1981 - val_loss: 0.1974\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.1966 - val_loss: 0.1959\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.1951 - val_loss: 0.1945\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1938 - val_loss: 0.1932\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.1925 - val_loss: 0.1920\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1913 - val_loss: 0.1908\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.1902 - val_loss: 0.1897\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.1891 - val_loss: 0.1886\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1880 - val_loss: 0.1876\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.1870 - val_loss: 0.1866\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1861 - val_loss: 0.1857\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1852 - val_loss: 0.1848\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1843 - val_loss: 0.1839\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.1834 - val_loss: 0.1831\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(32, activation='sigmoid')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "encoder = Model(input=input_img, output=encoded)\n",
    "encoded_input = Input(shape=(32,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "##\n",
    "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "hist = autoencoder.fit(X_train,X_train,epochs=50,batch_size=32,validation_data=(X_val,X_val))\n",
    "autoencoder.save('basic_autoencoder_768x32.h5')\n",
    "#save other stuffs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección b) Se comparan visialmente la reconstrucción que logra realizar el autoencoder. Determinar si la percepción visual se corresponde con el error de reconstrucción que se observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4f6edeb381e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'basic_autoencoder_768x32.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#load other stuff ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mencoded_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdecoded_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "autoencoder = load_model('basic_autoencoder_768x32.h5')\n",
    "#load other stuff ...\n",
    "encoded_test = encoder.predict(X_test)\n",
    "decoded_test = decoder.predict(encoded_test)\n",
    "import matplotlib\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28),cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = plt.subplot(2, n, i + 1 + 2*n)\n",
    "    plt.imshow(decoded_test[i].reshape(28, 28),cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección c) Se verifica la calidad de la representación obtenida, para ello se construye un clasificador kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy PCA 0.90\n",
      "Classification Accuracy 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pca = PCA(n_components=10)\n",
    "#PCA\n",
    "pca.fit(X_train)\n",
    "pca_train = pca.transform(X_train)\n",
    "pca_test = pca.transform(X_test)\n",
    "#AUTOENCODER\n",
    "encoded_train = encoder.predict(X_train)\n",
    "encoded_test = encoder.predict(X_test)\n",
    "#CLASIFICATION\n",
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(pca_train, Y_train)\n",
    "print ('Classification Accuracy PCA %.2f' % clf.score(pca_test,Y_test))\n",
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(encoded_train, Y_train)\n",
    "print ('Classification Accuracy %.2f' % clf.score(encoded_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección d) Deep encoding, se experimenta el uso de más de dos capas ocultas para demostrar que mejora la compresión obtenida por PCA, utilizando el mismo número de dimensiones. Para ello se prueba con $d \\in [2,4,8,16]$ y distintas profundidades $L \\in [2,3,4]$ y se compara el desempeño tanto en el error de reconstrucción como en clasificación via kNN de cada representación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2 #try other and do a nice plot\n",
    "input_img = Input(shape=(784,))\n",
    "encoded1 = Dense(1000, activation='relu')(input_img)\n",
    "encoded2 = Dense(500, activation='relu')(encoded1)\n",
    "encoded3 = Dense(250, activation='relu')(encoded2)\n",
    "encoded4 = Dense(target_dim, activation='relu')(encoded3)\n",
    "decoded4 = Dense(250, activation='relu')(encoded4)\n",
    "decoded3 = Dense(500, activation='relu')(encoded3)\n",
    "decoded2 = Dense(1000, activation='relu')(decoded3)\n",
    "decoded1 = Dense(784, activation='sigmoid')(decoded2)\n",
    "autoencoder = Model(input=input_img, output=decoded1)\n",
    "encoder = Model(input=input_img, output=encoded3)\n",
    "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train,x_train,epochs=40,batch_size=32,validation_data=(x_val,x_val))\n",
    "autoencoder.save('my_autoencoder_768x1000x500x250x2.h5')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pca = PCA(n_components=target_dim)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección e) Se elije una de las representaciones anteriores y se visualizan usando la herramienta TSNE disponible en la librería sklearn. Para proceder con una comparación cualitativa de los resultados obtenidos mediante PCA y AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplot=5000 #warning: mind your memory!\n",
    "encoded_train = encoder.predict(x_train[:nplot])\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "encoded_train = model.fit_transform(encoded_train)\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors={0:'b',1:'g',2:'r',3:'c',4:'m',5:'y',6:'k',7:'orange',8:'darkgreen',9:'maroon'}\n",
    "markers={0:'o',1:'+',2: 'v',3:'<',4:'>',5:'^',6:'s',7:'p',8:'*',9:'x'}\n",
    "for idx in xrange(0,nplot):\n",
    "    label = y_train[idx]\n",
    "    line = plt.plot(encoded_train[idx][0], encoded_train[idx][1],\n",
    "        color=colors[label], marker=markers[label], markersize=6)\n",
    "pca_train = pca.transform(x_train)\n",
    "encoded_train = pca_train[:nplot]\n",
    "... #plot PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección f) Por ultimo se modifica el primer autoencoder (a) para trabajar directamente sobre las  imágenes de MNIST, sin tratarlas como vectores, sino como matrices de tamaño 1 x 28 x 28. Es posible utilizando capas convolucionales para definir el Encoder y el Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = x_train.astype('float32') / 255.\n",
    "X_test_ = x_test.astype('float32') / 255.\n",
    "X_train_ = np.reshape(x_train, (len(x_train), 28, 28, 1)) #modify for th dim ordering\n",
    "X_test_ = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "input_img_ = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img_)\n",
    "x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
