{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T20:24:11.190237Z",
     "start_time": "2018-08-28T20:23:54.939415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 60, 64)       2691776     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)          (None, 60, 128)      74496       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 60, 47)       6063        cu_dnngru_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 47, 60)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 60)       0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 60, 47)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 47, 128)      0           cu_dnngru_1[0][0]                \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)          (None, 47, 128)      99072       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 47, 47423)    6117567     cu_dnngru_2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,988,974\n",
      "Trainable params: 8,988,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time, os, pickle, json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input,RepeatVector,TimeDistributed,Dense,Embedding,Flatten,Activation,Permute,Lambda\n",
    "from keras.layers import CuDNNGRU\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'temp','Xtrain_question.pickle'),'rb') as p_file:\n",
    "    Xtrain_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','Xtest_question.pickle'),'rb') as p_file:\n",
    "    Xtest_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','X_answers.pickle'),'rb') as p_file:\n",
    "    X_answers = pickle.load(p_file)\n",
    "\n",
    "input_var = json.load(open(os.path.join(os.getcwd(),'temp','input_var.json'),'rb'))\n",
    "\n",
    "lenght_output = len(Xtrain_question[0])\n",
    "hidden_dim = 128\n",
    "embedding_vector = 64\n",
    "max_input_lenght = int(input_var['max_input_lenght'])\n",
    "max_output_lenght = int(input_var['max_output_lenght'])\n",
    "input_dim = int(input_var['input_dim'])\n",
    "output_dim = int(input_var['out_dim'])\n",
    "\n",
    "encoder_input = Input(shape=(max_input_lenght,))\n",
    "embedded = Embedding(input_dim=input_dim,output_dim=embedding_vector,input_length=max_input_lenght)(encoder_input)\n",
    "encoder = CuDNNGRU(hidden_dim, return_sequences=True)(embedded)\n",
    "\n",
    "attention = TimeDistributed(Dense(max_output_lenght, activation='tanh'))(encoder)\n",
    "\n",
    "attention = Permute([2, 1])(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "\n",
    "\n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention, encoder, axes=1)\n",
    "\n",
    "\n",
    "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
    "decoder = CuDNNGRU(hidden_dim, return_sequences=True)(sent_representation)\n",
    "#probabilities = TimeDistributed(Dense(len(vocab_answer), activation=\"softmax\"))(decoder)\n",
    "probabilities = TimeDistributed(Dense(output_dim, activation=\"softmax\"))(decoder)\n",
    "\n",
    "model = Model(encoder_input,probabilities)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(),'results')):\n",
    "   os.makedirs(os.path.join(os.getcwd(),'results'))\n",
    "\n",
    "plot_model(model, to_file=os.path.join(os.getcwd(),'results','model_CuDNNGRU.png'))\n",
    "\n",
    "X_answers = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
    "#X_answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T23:09:48.976085Z",
     "start_time": "2018-08-28T20:27:44.771573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69456 samples, validate on 17365 samples\n",
      "Epoch 1/10\n",
      "69456/69456 [==============================] - 977s 14ms/step - loss: 0.9733 - val_loss: 0.7923\n",
      "Epoch 2/10\n",
      "69456/69456 [==============================] - 975s 14ms/step - loss: 0.6849 - val_loss: 0.7996\n",
      "Epoch 3/10\n",
      "69456/69456 [==============================] - 973s 14ms/step - loss: 0.6692 - val_loss: 0.8047\n",
      "Epoch 4/10\n",
      "69456/69456 [==============================] - 972s 14ms/step - loss: 0.6564 - val_loss: 0.8116\n",
      "Epoch 5/10\n",
      "69456/69456 [==============================] - 971s 14ms/step - loss: 0.6443 - val_loss: 0.8206\n",
      "Epoch 6/10\n",
      "69456/69456 [==============================] - 971s 14ms/step - loss: 0.6302 - val_loss: 0.8296\n",
      "Epoch 7/10\n",
      "69456/69456 [==============================] - 970s 14ms/step - loss: 0.6128 - val_loss: 0.8282\n",
      "Epoch 8/10\n",
      "69456/69456 [==============================] - 972s 14ms/step - loss: 0.5946 - val_loss: 0.8433\n",
      "Epoch 9/10\n",
      "69456/69456 [==============================] - 970s 14ms/step - loss: 0.5772 - val_loss: 0.8474\n",
      "Epoch 10/10\n",
      "69456/69456 [==============================] - 972s 14ms/step - loss: 0.5607 - val_loss: 0.8571\n"
     ]
    }
   ],
   "source": [
    "model_history = defaultdict(list)\n",
    "start = time.time()\n",
    "model_history['history'] = model.fit(Xtrain_question,X_answers,epochs=10,batch_size=64,validation_split=0.2)\n",
    "end = time.time()-start\n",
    "model_history['time'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T00:31:36.145724Z",
     "start_time": "2018-08-29T00:31:35.999738Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join(os.getcwd(),'results','model_CuDNNGRU_.h5'))\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'results','model_CuDNNGRU_history.pickle'), 'wb') as r_file:\n",
    "    pickle.dump(model_history['history'].history,r_file)\n",
    "with open(os.path.join(os.getcwd(),'results','model_CuDNNGRU_time.pickle'), 'wb') as r_file:\n",
    "    pickle.dump(model_history['time'],r_file)\n",
    "#model.save(os.path.join(os.getcwd(),'results','model_CuDNNGRU_.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
