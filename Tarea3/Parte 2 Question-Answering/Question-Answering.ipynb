{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T02:29:09.308433Z",
     "start_time": "2018-08-28T02:29:09.290504Z"
    }
   },
   "source": [
    "## 2. *Question Answering*\n",
    "\n",
    "Las redes neuronales recurrentes hoy en día han sido aplicadas a varios problemas que involucra dependencia temporal de los datos de entrada, en textos por lo común, tal como los modelos *sequence to sequence* de traducción, resumir textos, formular hipótesis de un extracto o, como veremos en esta actividad, generar respuesta en base a alguna pregunta. En imágenes también han sido aplicadas, ya sea a procesamiento de videos u a otro problema en que las imágenes tienen dependencia temporal unas con otras.\n",
    "\n",
    "Para ésta actividad trabajaremos el dataset de __[SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)__  (The Stanford Question Answering Dataset), los datos se los entregamos en formato *csv*, sin ningún preprocesamiento, para que sea mas fácil la lectura. La tarea como ya se comentó consiste en predecir una respuesta (secuencia de palabras) que contesten una pregunta también en forma de secuencia de palabras, con un enfoque *encoder-decoder* con módulos de antención.\n",
    "\n",
    "\n",
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/07/20/sockeye_1.gif\" title=\"Attention\" width=\"65%\" style=\"float: right;\"/>\n",
    "\n",
    "\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png\" title=\"Attention\" width=\"35%\" style=\"float: left;\"/>\n",
    "\n",
    "\n",
    "\n",
    "Los módulos de antención [[6]](#refs) son una variación a la arquitectura *encoder-decoder* en donde se agrega que para cada instante de tiempo de la **decodificación** $T'$ hay una combinación lineal del vector de codificación en todos los instantes tiempo $T$, ésto es para que en cada instante de tiempo de la decodificación se ponga atención a cierta información en toda la secuencia de entrada. \n",
    "\n",
    "\n",
    "$$\n",
    "y_{T'} = \\sum_{t}^{T} \\alpha_{T',t} \\cdot h_t^{codificacion}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Carge los datos y descríbalos ¿Cuántos ejemplos se tienen para entrenar y para predecir?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T02:59:17.237578Z",
     "start_time": "2018-08-28T02:59:17.042004Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(os.getcwd(),'data','train_Q-A.csv'))\n",
    "df_train.dropna(inplace=True)\n",
    "df_test = pd.read_csv(os.path.join(os.getcwd(),'data','test_Q.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T02:59:24.144247Z",
     "start_time": "2018-08-28T02:59:24.136268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "2  56be85543aeaaa14008c9066   \n",
       "3  56bf6b0f3aeaaa14008c9601   \n",
       "4  56bf6b0f3aeaaa14008c9602   \n",
       "\n",
       "                                            question               answer  \n",
       "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas  \n",
       "4         In which decade did Beyonce become famous?           late 1990s  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T02:59:32.256291Z",
     "start_time": "2018-08-28T02:59:32.248313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56ddde6b9a695914005b962a</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56ddde6b9a695914005b962b</td>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56ddde6b9a695914005b962c</td>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                           question\n",
       "0  56ddde6b9a695914005b9628               In what country is Normandy located?\n",
       "1  56ddde6b9a695914005b9629                 When were the Normans in Normandy?\n",
       "2  56ddde6b9a695914005b962a      From which countries did the Norse originate?\n",
       "3  56ddde6b9a695914005b962b                          Who was the Norse leader?\n",
       "4  56ddde6b9a695914005b962c  What century did the Normans first gain their ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Realice un preprocesamiento simple a los textos de entrada (preguntas) *tokenizandolos* y pasando a minúsculas para evitar ambiguedad, si desea agregar algun preprocesamiento éxtra ésto se verá reflajado en su nota. A los textos de salida (respuestas) no realice ningún preprocesamiento mas que *tokenizar*, puesto que para la evaluación se solicita retornar los textos en su forma natural. Comente lo realizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T03:31:48.560399Z",
     "start_time": "2018-08-28T03:31:33.905661Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "train_questions = [word_tokenize(sentence.lower()) for sentence in df_train[\"question\"]] #or processing\n",
    "test_questions = [word_tokenize(sentence.lower()) for sentence in df_test[\"question\"]]\n",
    "train_answers = [word_tokenize(sentence) for sentence in df_train[\"answer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Cree un vocabulario para codificar las palabras en las respuestas a generar. Repita el procedimiento para las preguntas. Agrege un símbolo que signifique el fin de la respuesta a generar, así para tener un criterio de cuando una respuesta, valga la redundancia, está efectivamente *respondida* ¿Cuántas palabras tiene el vocabulario de las respuestas y de las preguntas? ¿Ésto podría ser un problema al momento de entrenar la red para que predizca de entre todas ellas?\n",
    "\n",
    "```python\n",
    "vocab_answer = set()\n",
    "for sentence in train_answers:\n",
    "    for word in sentence:\n",
    "        vocab_answer.add(word)\n",
    "vocab_answer = [\"#end\"]+ list(vocab_answer)\n",
    "print('posibles palabras para respuestas :', len(vocab_answer))\n",
    "vocabA_indices = {c: i for i, c in enumerate(vocab_answer)}\n",
    "indices_vocabA = {i: c for i, c in enumerate(vocab_answer)}\n",
    "#sameforquestions\n",
    "```\n",
    "\n",
    "> d) Codifique los tokens (palabras) de cada texto que utilizará.\n",
    "\n",
    "```python\n",
    "#input and output to onehotvector\n",
    "X_answers = [[vocabA_indices[palabra] for palabra in sentence] for sentence in train_answers]\n",
    "Xtrain_question = #same for train question\n",
    "Xtest_question = #same for test question\n",
    "```\n",
    "> Luego de ésto realice un *padding* a ambas secuencias, entrada y salida de entrenamiento y a la entrada del conjunto de pruebas. Comente sobre las dimensionalidades finales de los conjuntos de entrenamiento y de prueba.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "max_input_lenght = np.max(list(map(len,train_questions)))\n",
    "max_output_lenght = np.max(list(map(len,train_answers)))+1\n",
    "from keras.preprocessing import sequence\n",
    "Xtrain_question = sequence.pad_sequences(Xtrain_question,maxlen=max_input_lenght,padding='pre or post',value=0)\n",
    "Xtest_question = sequence.pad_sequences(Xtest_question,maxlen=max_input_lenght,padding='pre or post',value=0)\n",
    "X_answers = sequence.pad_sequences(X_answers,maxlen=max_output_lenght,padding='post',value=vocabA_indices[\"#end\"])\n",
    "```\n",
    "\n",
    "> e) Defina el modelo *encoder-decoder* con los módulos de atención.\n",
    "\n",
    "```python\n",
    "#Encoder-Decoder modelo\n",
    "from keras.layers import Input,RepeatVector,TimeDistributed,Dense,Embedding,Flatten,Activation,Permute,Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "lenght_output = max_output_lenght\n",
    "hidden_dim = 128\n",
    "```\n",
    "> Defina el *encoder* y las compuertas que utilizará: CuDNNGRU,CuDNNLSTM, RNN u otra. Puede utilizar redes bidireccionales en el *encoder* ¿Esto mejora el resultado?\n",
    "\n",
    "```python\n",
    "embedding_vector = 64 \n",
    "encoder_input = Input(shape=(max_input_lenght,))\n",
    "embedded = Embedding(input_dim=len(vocabQ_indices),output_dim=embedding_vector,input_length=max_input_lenght)(encoder_input)\n",
    "encoder = gate(hidden_dim, return_sequences=True)(embedded)\n",
    "```\n",
    "> Defina la atención $\\alpha$ que se calculará sobre cada instante de tiempo $T$ computándo su atención en cada instante de tiempo de la decodificación $T'$.\n",
    "\n",
    "```python\n",
    "# compute T' importance for each step T\n",
    "attention = TimeDistributed(Dense(max_output_lenght, activation='tanh'))(encoder)\n",
    "#softmax a las antenciones sobre todo T\n",
    "attention = Permute([2, 1])(attention)\n",
    "attention = Activation('softmax')(attention) \n",
    "attention = Permute([2, 1])(attention)\n",
    "```\n",
    "> Aplique la atención sobre el *encoder* y genere las salidas correspondientes.\n",
    "\n",
    "```python\n",
    "# apply the attention to encoder\n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention,encoder, axes=1)\n",
    "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
    "decoder = gate(hidden_dim, return_sequences=True)(sent_representation)\n",
    "probabilities = TimeDistributed(Dense(len(vocab_answer), activation=\"softmax\"))(decoder)\n",
    "```\n",
    "> Defina el modelo y descríbalo adecuadamente.\n",
    "\n",
    "```python\n",
    "model = Model(encoder_input,probabilities)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "> f) Entrene el modelo por 10 *epochs* con el tamaño de batch que estime conveniente. Para ésto deberá redimensionar la salida para que tenga 3 dimensiones debido a la recurrencia.\n",
    "\n",
    "```python\n",
    "X_answers = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
    "X_answers.shape\n",
    "model.fit(Xtrain_question,X_answers,epochs=10,batch_size=BS,validation_split=0.2)\n",
    "```\n",
    "*Por temas de recursos puede optar con entrenar con una muestra más pequeña del conjunto de entrenamiento*.\n",
    "\n",
    "> g) Muestre ejemplos de la predicción del modelo, para ésto genere una función que prediga a través de la distribución de probabilidad de la salida, de la forma que estime conveniente, cada palabra en cada instante de tiempo.\n",
    "\n",
    "```python\n",
    "def predict_words(model,example,diversity=?):\n",
    "    #predict example\n",
    "n=10\n",
    "for i in range(n):\n",
    "    indexs = np.random.randint(0,len(Xtest_question))\n",
    "    example = Xtest_question[indexs]\n",
    "    indexes_answer = predict_words(model,example,0.85)\n",
    "    question = df_test[\"question\"][indexs]\n",
    "    print(\"Pregunta: \",question)\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    print(\"Respuesta: \",answer)\n",
    "print(\"Los ha predecido todos!\")\n",
    "```\n",
    "\n",
    "> h) Evalúe la calidad de su modelo con la métrica del *benchmark*, para ésto deberá descargar el archivo **evaluation script** y el dato **dev json** de la página oficial del dataset: https://rajpurkar.github.io/SQuAD-explorer/ y ejecutarlo de la siguiente manera dentro del *Jupyter Notebook*\n",
    "\n",
    "```python\n",
    "#evaluar resultados\n",
    "!python evaluate-v2.0.py dev-v2.0.json predictions\n",
    "```\n",
    "> Para generar las predicciones utilice la función anteriormente definida de la siguiente manera:\n",
    "```python\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    indexes_answer = predict_words(model,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "    contador+=1\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()\n",
    "```\n",
    "Comente sobre el desempeño obtenido y porqué debiera deberse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
