{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T11:08:42.857943Z",
     "start_time": "2018-08-31T11:08:42.851959Z"
    }
   },
   "source": [
    "# Tarea 3 - Parte 2\n",
    "# INF477 Redes Neuronales Artificiales I-2018\n",
    "\n",
    "Profesor: Dr. Ricardo Ñanculef -- \n",
    "Ayudante: Francisco Mena\n",
    "\n",
    "Alumnos:\n",
    "- Jose Caimapo, jose.caimapo.12@sansano.usm.cl\n",
    "\n",
    "- Eliana Providel Godoy, eprovide@inf.utfsm.cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte se realiza solo la predicción de los modelos ya entrenados con anterioridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T11:15:41.401727Z",
     "start_time": "2018-08-31T11:15:40.025160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from collections import defaultdict\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T11:16:11.230686Z",
     "start_time": "2018-08-31T11:16:01.591271Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8e694d178b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresultados_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultados_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model_CuDNNGRU_.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultados_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model_CuDNNLSTM_.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultados_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model_RNN_.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#model4 = load_model(os.path.join(resultados_path,'model_Bidirectional_.h5'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m    926\u001b[0m                              ' elements.')\n\u001b[0;32m    927\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 928\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2438\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2439\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2440\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resultados_path = os.path.join(os.getcwd(),'results')\n",
    "model1 = load_model(os.path.join(resultados_path,'model_CuDNNGRU_.h5'))\n",
    "model2 = load_model(os.path.join(resultados_path,'model_CuDNNLSTM_.h5'))\n",
    "model3 = load_model(os.path.join(resultados_path,'model_RNN_.h5'))\n",
    "#model4 = load_model(os.path.join(resultados_path,'model_Bidirectional_.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:28.806926Z",
     "start_time": "2018-08-31T00:26:28.715146Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(os.getcwd(),'data','test_Q.csv'))\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'temp','Xtest_question.pickle'),'rb') as p_file:\n",
    "    Xtest_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocab_answer.pickle'),'rb') as p_file:\n",
    "    vocab_answer = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocab_question.pickle'),'rb') as p_file:\n",
    "    vocab_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocabQ_indices.pickle'),'rb') as p_file:\n",
    "    vocabQ_indices = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','indices_vocabA.pickle'),'rb') as p_file:\n",
    "    indices_vocabA = pickle.load(p_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:29.506704Z",
     "start_time": "2018-08-31T00:26:29.499723Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_words(model, example):\n",
    "    prediction = model.predict(example)\n",
    "    prediction = prediction.reshape(prediction.shape[1:])\n",
    "    palabra_elegida = np.array([])\n",
    "    for p_palabra in prediction:\n",
    "        p_palabra = p_palabra/np.sum(p_palabra)\n",
    "        palabra_elegida = np.append(\n",
    "            palabra_elegida, np.random.choice(p_palabra.shape[0], p=p_palabra))\n",
    "    return palabra_elegida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:30.817085Z",
     "start_time": "2018-08-31T00:26:30.804105Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_examples(model, indexs):\n",
    "\n",
    "    for i in range(len(indexs)):\n",
    "        #indexs = np.random.randint(0,len(Xtest_question))\n",
    "        example = Xtest_question[indexs[i]]\n",
    "        example = example.reshape((1,60,))\n",
    "        indexes_answer = predict_words(model, example)\n",
    "\n",
    "        question = df_test[\"question\"][indexs[i]]\n",
    "        print(\"Pregunta: \", question)\n",
    "        answer = \"\"\n",
    "        for index in indexes_answer:\n",
    "            if indices_vocabA[index] == \"#end\":  # el final de la oracion\n",
    "                continue\n",
    "            else:\n",
    "                answer += indices_vocabA[indexs[i]] + \" \"\n",
    "        print(\"Respuesta: \", answer)\n",
    "    print(\"Los ha predecido todos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:32.446465Z",
     "start_time": "2018-08-31T00:26:32.442466Z"
    }
   },
   "outputs": [],
   "source": [
    "tipos=np.random.randint(0,len(Xtest_question),size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:36.137486Z",
     "start_time": "2018-08-31T00:26:34.831980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What is the force between two locations related to?\n",
      "Respuesta:  Patience \n",
      "Pregunta:  What caused UK to have an oil crisis in its own country?\n",
      "Respuesta:  768,868 768,868 768,868 768,868 \n",
      "Pregunta:  Were the centers profitable\n",
      "Respuesta:  subcutaneously subcutaneously subcutaneously subcutaneously subcutaneously subcutaneously \n",
      "Pregunta:  What is located after Rüdesheim am Rhein and Koblenz?\n",
      "Respuesta:  justify justify justify justify justify justify \n",
      "Pregunta:  What type of company is Van Gend en Loos?\n",
      "Respuesta:  handpump handpump handpump handpump handpump \n",
      "Pregunta:  What is considered to be a recreational euphoric?\n",
      "Respuesta:  Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten \n",
      "Pregunta:  What are other irrelevant examples of a function problem>\n",
      "Respuesta:  multi-racials multi-racials multi-racials \n",
      "Pregunta:  How much of the water flow does the Waal get from the Rhine?\n",
      "Respuesta:  marshmallows marshmallows \n",
      "Pregunta:  Who asserted Russia's right to \"self-determination?\"\n",
      "Respuesta:  brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket \n",
      "Pregunta:  What well known political scientists are currently on the university's faculty?\n",
      "Respuesta:  tornadoes tornadoes tornadoes tornadoes \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model1,tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:39.046503Z",
     "start_time": "2018-08-31T00:26:38.516918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What is the force between two locations related to?\n",
      "Respuesta:  Patience \n",
      "Pregunta:  What caused UK to have an oil crisis in its own country?\n",
      "Respuesta:  768,868 \n",
      "Pregunta:  Were the centers profitable\n",
      "Respuesta:  subcutaneously subcutaneously subcutaneously subcutaneously \n",
      "Pregunta:  What is located after Rüdesheim am Rhein and Koblenz?\n",
      "Respuesta:  justify justify justify justify justify justify justify justify \n",
      "Pregunta:  What type of company is Van Gend en Loos?\n",
      "Respuesta:  handpump handpump handpump handpump handpump handpump handpump handpump handpump handpump handpump handpump \n",
      "Pregunta:  What is considered to be a recreational euphoric?\n",
      "Respuesta:  Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten Garten \n",
      "Pregunta:  What are other irrelevant examples of a function problem>\n",
      "Respuesta:  multi-racials multi-racials \n",
      "Pregunta:  How much of the water flow does the Waal get from the Rhine?\n",
      "Respuesta:  marshmallows marshmallows \n",
      "Pregunta:  Who asserted Russia's right to \"self-determination?\"\n",
      "Respuesta:  brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket \n",
      "Pregunta:  What well known political scientists are currently on the university's faculty?\n",
      "Respuesta:  tornadoes tornadoes \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model2,tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:26:43.172367Z",
     "start_time": "2018-08-31T00:26:42.387467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What is the force between two locations related to?\n",
      "Respuesta:  Patience \n",
      "Pregunta:  What caused UK to have an oil crisis in its own country?\n",
      "Respuesta:  768,868 \n",
      "Pregunta:  Were the centers profitable\n",
      "Respuesta:  subcutaneously subcutaneously subcutaneously \n",
      "Pregunta:  What is located after Rüdesheim am Rhein and Koblenz?\n",
      "Respuesta:  justify justify \n",
      "Pregunta:  What type of company is Van Gend en Loos?\n",
      "Respuesta:  handpump handpump handpump \n",
      "Pregunta:  What is considered to be a recreational euphoric?\n",
      "Respuesta:  Garten Garten \n",
      "Pregunta:  What are other irrelevant examples of a function problem>\n",
      "Respuesta:  multi-racials \n",
      "Pregunta:  How much of the water flow does the Waal get from the Rhine?\n",
      "Respuesta:  marshmallows marshmallows \n",
      "Pregunta:  Who asserted Russia's right to \"self-determination?\"\n",
      "Respuesta:  brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket brocket \n",
      "Pregunta:  What well known political scientists are currently on the university's faculty?\n",
      "Respuesta:  tornadoes \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model3,tipos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones son relativamente parecidas en la eleccion de palabras, pero son diferentes en la elección del fin de la oración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:36:06.593750Z",
     "start_time": "2018-08-31T00:28:56.203043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model1,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions1\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:44:10.262938Z",
     "start_time": "2018-08-31T00:36:44.428276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model2,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions2\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T01:17:07.517148Z",
     "start_time": "2018-08-31T01:04:49.971103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model3,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions3\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "429px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
