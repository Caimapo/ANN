{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T11:08:42.857943Z",
     "start_time": "2018-08-31T11:08:42.851959Z"
    }
   },
   "source": [
    "# Tarea 3 - Parte 2\n",
    "# INF477 Redes Neuronales Artificiales I-2018\n",
    "\n",
    "Profesor: Dr. Ricardo Ñanculef -- \n",
    "Ayudante: Francisco Mena\n",
    "\n",
    "Alumnos:\n",
    "- Jose Caimapo, jose.caimapo.12@sansano.usm.cl\n",
    "\n",
    "- Eliana Providel Godoy, eprovide@inf.utfsm.cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte se realiza solo la predicción de los modelos ya entrenados con anterioridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:05:27.802695Z",
     "start_time": "2018-09-01T01:05:26.560015Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\caimapo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from collections import defaultdict\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:05:44.878924Z",
     "start_time": "2018-09-01T01:05:29.601497Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultados_path = os.path.join(os.getcwd(),'results')\n",
    "model1 = load_model(os.path.join(resultados_path,'model_CuDNNGRU_.h5'))\n",
    "model2 = load_model(os.path.join(resultados_path,'model_CuDNNLSTM_.h5'))\n",
    "model3 = load_model(os.path.join(resultados_path,'model_RNN_.h5'))\n",
    "#model4 = load_model(os.path.join(resultados_path,'model_Bidirectional_.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:07:13.161835Z",
     "start_time": "2018-09-01T01:07:13.066983Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(os.getcwd(),'data','test_Q.csv'))\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'temp','Xtest_question.pickle'),'rb') as p_file:\n",
    "    Xtest_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocab_answer.pickle'),'rb') as p_file:\n",
    "    vocab_answer = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocab_question.pickle'),'rb') as p_file:\n",
    "    vocab_question = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','vocabQ_indices.pickle'),'rb') as p_file:\n",
    "    vocabQ_indices = pickle.load(p_file)\n",
    "with open(os.path.join(os.getcwd(),'temp','indices_vocabA.pickle'),'rb') as p_file:\n",
    "    indices_vocabA = pickle.load(p_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:08:25.295042Z",
     "start_time": "2018-09-01T01:08:25.284034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se define diversity como la probabilidad de elegir otra elemento entre el segundo al cuarto con mas probabilidad\n",
    "def predict_words(model, example,diversity=0):\n",
    "    prediction = model.predict(example)\n",
    "    prediction = prediction.reshape(prediction.shape[1:])\n",
    "    palabra_elegida = np.array([])\n",
    "    for p_palabra in prediction:\n",
    "        p_palabra = p_palabra/np.sum(p_palabra)\n",
    "        palabra_elegida = np.append(\n",
    "            palabra_elegida, np.random.choice(p_palabra.shape[0], p=p_palabra))\n",
    "        if np.random.binomial(n=1,p=diversity):\n",
    "            palabra_elegida = palabra_elegida[:-1]\n",
    "            idx = np.random.randint(2,4)\n",
    "            palabra_elegida = np.append(\n",
    "            palabra_elegida, np.argsort(p_palabra)[::-1][idx])\n",
    "            \n",
    "    return palabra_elegida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:09:39.032287Z",
     "start_time": "2018-09-01T01:09:39.019315Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_examples(model, indexs):\n",
    "\n",
    "    for i in range(len(indexs)):\n",
    "        #indexs = np.random.randint(0,len(Xtest_question))\n",
    "        example = Xtest_question[indexs[i]]\n",
    "        example = example.reshape((1,60,))\n",
    "        indexes_answer = predict_words(model, example, diversity=0.0)\n",
    "\n",
    "        question = df_test[\"question\"][indexs[i]]\n",
    "        print(\"Pregunta: \", question)\n",
    "        answer = \"\"\n",
    "        for index in indexes_answer:\n",
    "            if indices_vocabA[index] == \"#end\":  # el final de la oracion\n",
    "                continue\n",
    "            else:\n",
    "                answer += indices_vocabA[indexs[i]] + \" \"\n",
    "        print(\"Respuesta: \", answer)\n",
    "    print(\"Los ha predecido todos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:09:22.957189Z",
     "start_time": "2018-09-01T01:09:22.954198Z"
    }
   },
   "outputs": [],
   "source": [
    "tipos=np.random.randint(0,len(Xtest_question),size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:09:41.008075Z",
     "start_time": "2018-09-01T01:09:40.618118Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What are the total number of votes to be counted during the voting process?\n",
      "Respuesta:  NetBase NetBase NetBase NetBase NetBase NetBase NetBase NetBase \n",
      "Pregunta:  What did the number of legions in Roman times depend on?\n",
      "Respuesta:  Mahoney Mahoney Mahoney \n",
      "Pregunta:  What was the goal of congress?\n",
      "Respuesta:  651 651 651 651 651 \n",
      "Pregunta:  How was US News and World Report ranked in terms of CEO positions in 2011?\n",
      "Respuesta:  Grimaldi Grimaldi \n",
      "Pregunta:  What group prepares the bid for work?\n",
      "Respuesta:  CLV \n",
      "Pregunta:  How many biomolecules contain no oxygen?\n",
      "Respuesta:  Danish Danish \n",
      "Pregunta:  What are many types of Turing machines not used for?\n",
      "Respuesta:  æ æ \n",
      "Pregunta:   What was the U.S. Information Agency charged with doing during the Warm War?\n",
      "Respuesta:  Großen Großen Großen Großen Großen Großen \n",
      "Pregunta:  What results in dioxygen's triplet bond character?\n",
      "Respuesta:  supplies supplies supplies supplies supplies supplies supplies supplies \n",
      "Pregunta:  What treaty is the Social Chapter not a chapter of?\n",
      "Respuesta:  Lythgoe Lythgoe Lythgoe Lythgoe Lythgoe \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model1,tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:08:48.527210Z",
     "start_time": "2018-09-01T01:08:47.458042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What, along with admission, exhaust, and compression, is an event in the steam cycle?\n",
      "Respuesta:  Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl \n",
      "Pregunta:  Which country was to pull back from the Sinai Peninsula?\n",
      "Respuesta:  59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 \n",
      "Pregunta:  Succeeding speakers are usually allotted more what?\n",
      "Respuesta:  Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes \n",
      "Pregunta:   When did Khan formally reject the Yuan dynasty?\n",
      "Respuesta:  Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo \n",
      "Pregunta:  When did the Iranian government not get a resurgence?\n",
      "Respuesta:  Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland \n",
      "Pregunta:  When was consumption inequality lower than it had been in 1986?\n",
      "Respuesta:  Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel \n",
      "Pregunta:  Where is cross-polarized light identified by petrologists?\n",
      "Respuesta:  Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace \n",
      "Pregunta:  How much was the combined wealth of the \"10 Million dollar millionaires\" in 2008?\n",
      "Respuesta:  acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted \n",
      "Pregunta:  How do physical experiments explain fluid inclusion data?\n",
      "Respuesta:  2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 \n",
      "Pregunta:  What author argues pitching the conscience versus the collective?\n",
      "Respuesta:  Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model2,tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T01:08:52.528227Z",
     "start_time": "2018-09-01T01:08:51.145926Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta:  What, along with admission, exhaust, and compression, is an event in the steam cycle?\n",
      "Respuesta:  Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl Uranyl \n",
      "Pregunta:  Which country was to pull back from the Sinai Peninsula?\n",
      "Respuesta:  59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 59,948 \n",
      "Pregunta:  Succeeding speakers are usually allotted more what?\n",
      "Respuesta:  Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes Prefixes \n",
      "Pregunta:   When did Khan formally reject the Yuan dynasty?\n",
      "Respuesta:  Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo Massimo \n",
      "Pregunta:  When did the Iranian government not get a resurgence?\n",
      "Respuesta:  Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland Somaliland \n",
      "Pregunta:  When was consumption inequality lower than it had been in 1986?\n",
      "Respuesta:  Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel Russel \n",
      "Pregunta:  Where is cross-polarized light identified by petrologists?\n",
      "Respuesta:  Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace Terrace \n",
      "Pregunta:  How much was the combined wealth of the \"10 Million dollar millionaires\" in 2008?\n",
      "Respuesta:  acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted acted \n",
      "Pregunta:  How do physical experiments explain fluid inclusion data?\n",
      "Respuesta:  2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 2,929 \n",
      "Pregunta:  What author argues pitching the conscience versus the collective?\n",
      "Respuesta:  Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado Jornado \n",
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "show_examples(model3,tipos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones son relativamente parecidas en la eleccion de palabras, pero son diferentes en la elección del fin de la oración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:36:06.593750Z",
     "start_time": "2018-08-31T00:28:56.203043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model1,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions1\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T00:44:10.262938Z",
     "start_time": "2018-08-31T00:36:44.428276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model2,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions2\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T01:17:07.517148Z",
     "start_time": "2018-08-31T01:04:49.971103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los ha predecido todos!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_predictions = {}\n",
    "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
    "    example = example.reshape((1,60,))\n",
    "    indexes_answer = predict_words(model3,example) #predice palabra en cada instante\n",
    "    answer = \"\"\n",
    "    for index in indexes_answer:\n",
    "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
    "            continue\n",
    "        else:\n",
    "            answer+=indices_vocabA[index]+\" \"\n",
    "    dic_predictions[id_e] = answer\n",
    "print(\"Los ha predecido todos!\")\n",
    "json_save = json.dumps(dic_predictions)\n",
    "archivo = open(\"predictions3\",\"w\")\n",
    "archivo.write(json_save)\n",
    "archivo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "429px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
